{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "a = tf.add(2, 3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(a))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "a = tf.add(3, 5)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7776, 10]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = 2\n",
    "y = 3\n",
    "op1 = tf.add(x, y)\n",
    "op2 = tf.mul(x, y)\n",
    "useless = tf.mul(x, op1)\n",
    "op3 = tf.pow(op2, op1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([op3, useless]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 91.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.device('/cpu:0'):\n",
    "    a = tf.constant([[1.0, 2.0, 3.0, 4.0, 5.0, 6.0]], name='a')\n",
    "    b = tf.transpose([[1.0, 2.0, 3.0, 4.0, 5.0, 6.0]], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "    \n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = tf.add(3, 5)\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "a = tf.constant(2, name=\"a\")\n",
    "b = tf.constant(3, name=\"b\")\n",
    "x = tf.add(a, b)\n",
    "print(x)\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('./graphs', sess.graph)\n",
    "    print(sess.run(x))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "a = tf.constant([2, 2], name=\"vector\")\n",
    "b = tf.constant([[0, 1], [2, 3]], name=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"vector:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"zeros:0\", shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(tf.zeros([2, 3], tf.int32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"zeros_like:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"ones:0\", shape=(2, 3), dtype=float32)\n",
      "Tensor(\"ones_like:0\", shape=(1, 2), dtype=int32)\n",
      "Tensor(\"Fill:0\", shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.zeros_like(a))\n",
    "print(tf.ones([2,3]))\n",
    "print(tf.ones_like([a]))\n",
    "print(tf.fill([2, 3], 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.  11.  12.  13.]\n",
      "[ 3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    a = tf.linspace(10.0, 13.0, 4, name=\"linspace\")\n",
    "    print(sess.run(a))\n",
    "    b = tf.range(3, 18, 1)\n",
    "    print(b.eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node {\n",
      "  name: \"my_cost\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\000\\200?\\000\\000\\000@\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "versions {\n",
      "  producer: 17\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "my_const = tf.constant([1.0, 2.0], name=\"my_cost\")\n",
    "print(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"scalar/read:0\", shape=(), dtype=int32)\n",
      "Tensor(\"vector/read:0\", shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(2, name=\"scalar\")\n",
    "b = tf.Variable([2, 3], name=\"vector\")\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"x/Assign\"\n",
      "op: \"Assign\"\n",
      "input: \"x\"\n",
      "input: \"x/initial_value\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT32\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_class\"\n",
      "  value {\n",
      "    list {\n",
      "      s: \"loc:@x\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"use_locking\"\n",
      "  value {\n",
      "    b: true\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"validate_shape\"\n",
      "  value {\n",
      "    b: true\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(10, name=\"x\")\n",
    "print(x.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.Variable(10, name=\"x\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(init))\n",
    "    \n",
    "init_x = tf.variables_initializer([x], name=\"init_x\")\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(init_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.67973882  1.67592382 -0.19071345 ..., -0.14574654 -0.44223377\n",
      "   0.74218744]\n",
      " [-0.54146373  0.02901861  1.43578041 ...,  1.01705205 -0.57781988\n",
      "   1.22830677]\n",
      " [-0.423354    0.05386667 -0.49277624 ...,  0.11439822  0.68545997\n",
      "   1.40931845]\n",
      " ..., \n",
      " [ 0.82350218 -0.14894831  0.83606714 ...,  1.39919233 -0.03350252\n",
      "  -0.09442876]\n",
      " [-1.65446961  1.38988781 -0.29375669 ...,  0.18888779  0.207692\n",
      "  -1.00480795]\n",
      " [-1.29408026 -0.37106529 -0.04787628 ..., -0.38714463  0.53728181\n",
      "   0.46684763]]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.truncated_normal([700, 10]))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    print(W.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "W = tf.Variable(10)\n",
    "assign_op = W.assign(100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    print(W.eval())\n",
    "    sess.run(assign_op)\n",
    "    print(W.eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "8\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "a = tf.Variable(2, name=\"a\")\n",
    "a_times_two_op = a.assign(a * 2)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(a_times_two_op))\n",
    "    print(sess.run(a_times_two_op))\n",
    "    print(sess.run(a_times_two_op))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "a = tf.constant(5.0)\n",
    "b = tf.constant(6.0)\n",
    "c = a * b\n",
    "print(c.eval())\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.  7.  8.]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "a = tf.placeholder(tf.float32, shape=[3])\n",
    "b = tf.constant([5, 5, 5], tf.float32)\n",
    "\n",
    "c = a + b\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c, {a:[1, 2, 3]}))\n",
    "    writer = tf.summary.FileWriter('./my_graph', sess.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(10, name=\"x\")\n",
    "y = tf.Variable(20, name=\"y\")\n",
    "z = tf.add(x, y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for _ in range(10):\n",
    "        print(sess.run(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   6.2   29. ]\n",
      " [   9.5   44. ]\n",
      " [  10.5   36. ]\n",
      " [   7.7   37. ]\n",
      " [   8.6   53. ]\n",
      " [  34.1   68. ]\n",
      " [  11.    75. ]\n",
      " [   6.9   18. ]\n",
      " [   7.3   31. ]\n",
      " [  15.1   25. ]\n",
      " [  29.1   34. ]\n",
      " [   2.2   14. ]\n",
      " [   5.7   11. ]\n",
      " [   2.    11. ]\n",
      " [   2.5   22. ]\n",
      " [   4.    16. ]\n",
      " [   5.4   27. ]\n",
      " [   2.2    9. ]\n",
      " [   7.2   29. ]\n",
      " [  15.1   30. ]\n",
      " [  16.5   40. ]\n",
      " [  18.4   32. ]\n",
      " [  36.2   41. ]\n",
      " [  39.7  147. ]\n",
      " [  18.5   22. ]\n",
      " [  23.3   29. ]\n",
      " [  12.2   46. ]\n",
      " [   5.6   23. ]\n",
      " [  21.8    4. ]\n",
      " [  21.6   31. ]\n",
      " [   9.    39. ]\n",
      " [   3.6   15. ]\n",
      " [   5.    32. ]\n",
      " [  28.6   27. ]\n",
      " [  17.4   32. ]\n",
      " [  11.3   34. ]\n",
      " [   3.4   17. ]\n",
      " [  11.9   46. ]\n",
      " [  10.5   42. ]\n",
      " [  10.7   43. ]\n",
      " [  10.8   34. ]\n",
      " [   4.8   19. ]]\n",
      "[  6.2   9.5  10.5   7.7   8.6  34.1  11.    6.9   7.3  15.1  29.1   2.2\n",
      "   5.7   2.    2.5   4.    5.4   2.2   7.2  15.1  16.5  18.4  36.2  39.7\n",
      "  18.5  23.3  12.2   5.6  21.8  21.6   9.    3.6   5.   28.6  17.4  11.3\n",
      "   3.4  11.9  10.5  10.7  10.8   4.8]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import xlrd\n",
    "\n",
    "tf.reset_default_graph()\n",
    "DATA_FILE = 'data/fire_theft.xls'\n",
    "\n",
    "# Phase 1: Assemble the graph\n",
    "# Step 1: read in data from the .xls file\n",
    "book = xlrd.open_workbook(DATA_FILE, encoding_override='utf-8')\n",
    "sheet = book.sheet_by_index(0)\n",
    "data = np.asarray([sheet.row_values(i) for i in range(1, sheet.nrows)])\n",
    "n_samples = sheet.nrows - 1\n",
    "print(data)\n",
    "print(data[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# step 2\n",
    "X = tf.placeholder(tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# step 3\n",
    "W = tf.Variable(initial_value=0, name=\"W\", dtype=tf.float32)\n",
    "b = tf.Variable(initial_value=0, name=\"b\", dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Y_predicted = X * W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loss = tf.square(Y - Y_predicted, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 2069.6319333978354\n",
      "Epoch 1: 2117.0123581953535\n",
      "Epoch 2: 2092.302723001866\n",
      "Epoch 3: 2068.5080461938464\n",
      "Epoch 4: 2045.591184088162\n",
      "Epoch 5: 2023.5146448101316\n",
      "Epoch 6: 2002.2447619835536\n",
      "Epoch 7: 1981.748338803649\n",
      "Epoch 8: 1961.9944411260742\n",
      "Epoch 9: 1942.9520116143283\n",
      "Epoch 10: 1924.5930823644712\n",
      "Epoch 11: 1906.8898800636332\n",
      "Epoch 12: 1889.8164505837929\n",
      "Epoch 13: 1873.347133841543\n",
      "Epoch 14: 1857.4588400604468\n",
      "Epoch 15: 1842.1278742424079\n",
      "Epoch 16: 1827.332495119955\n",
      "Epoch 17: 1813.0520579712022\n",
      "Epoch 18: 1799.2660847636982\n",
      "Epoch 19: 1785.9562132299961\n",
      "Epoch 20: 1773.1024853109072\n",
      "Epoch 21: 1760.689129482884\n",
      "Epoch 22: 1748.6984157081515\n",
      "Epoch 23: 1737.1138680398553\n",
      "Epoch 24: 1725.920873066732\n",
      "Epoch 25: 1715.1046249579008\n",
      "Epoch 26: 1704.6500954309377\n",
      "Epoch 27: 1694.5447134910141\n",
      "Epoch 28: 1684.7746311347667\n",
      "Epoch 29: 1675.328450968245\n",
      "Epoch 30: 1666.1935385839038\n",
      "Epoch 31: 1657.3584002084322\n",
      "Epoch 32: 1648.8122658529207\n",
      "Epoch 33: 1640.5440742547091\n",
      "Epoch 34: 1632.5446836102221\n",
      "Epoch 35: 1624.8043315147183\n",
      "Epoch 36: 1617.3126799958602\n",
      "Epoch 37: 1610.0622532456405\n",
      "Epoch 38: 1603.0433557207386\n",
      "Epoch 39: 1596.2479176106197\n",
      "Epoch 40: 1589.668056331575\n",
      "Epoch 41: 1583.2965242617897\n",
      "Epoch 42: 1577.126371285745\n",
      "Epoch 43: 1571.1501190634\n",
      "Epoch 44: 1565.360979151513\n",
      "Epoch 45: 1559.7523780798629\n",
      "Epoch 46: 1554.3184364555138\n",
      "Epoch 47: 1549.0529469620615\n",
      "Epoch 48: 1543.950059985476\n",
      "Epoch 49: 1539.0050282141283\n",
      "Epoch 50: 1534.211797797609\n",
      "Epoch 51: 1529.56534988646\n",
      "Epoch 52: 1525.0607591186251\n",
      "Epoch 53: 1520.6934648507852\n",
      "Epoch 54: 1516.4585935090713\n",
      "Epoch 55: 1512.3524023861364\n",
      "Epoch 56: 1508.3695780125756\n",
      "Epoch 57: 1504.5066588066873\n",
      "Epoch 58: 1500.7606269073274\n",
      "Epoch 59: 1497.126336559476\n",
      "Epoch 60: 1493.600210891061\n",
      "Epoch 61: 1490.1794991287668\n",
      "Epoch 62: 1486.8605145300749\n",
      "Epoch 63: 1483.639419928193\n",
      "Epoch 64: 1480.5144186365596\n",
      "Epoch 65: 1477.4811065652452\n",
      "Epoch 66: 1474.5376660533782\n",
      "Epoch 67: 1471.6799176652871\n",
      "Epoch 68: 1468.9063155567717\n",
      "Epoch 69: 1466.2136880280007\n",
      "Epoch 70: 1463.5996563179153\n",
      "Epoch 71: 1461.0614086978492\n",
      "Epoch 72: 1458.597208841216\n",
      "Epoch 73: 1456.2043069711044\n",
      "Epoch 74: 1453.8807724802089\n",
      "Epoch 75: 1451.6242183893032\n",
      "Epoch 76: 1449.432753210976\n",
      "Epoch 77: 1447.3042320180018\n",
      "Epoch 78: 1445.237068621615\n",
      "Epoch 79: 1443.228872676177\n",
      "Epoch 80: 1441.2782130186733\n",
      "Epoch 81: 1439.3831422174615\n",
      "Epoch 82: 1437.542224922173\n",
      "Epoch 83: 1435.7540219968096\n",
      "Epoch 84: 1434.0160684508405\n",
      "Epoch 85: 1432.3276573866606\n",
      "Epoch 86: 1430.687153330871\n",
      "Epoch 87: 1429.093016880254\n",
      "Epoch 88: 1427.543719962062\n",
      "Epoch 89: 1426.038033108981\n",
      "Epoch 90: 1424.5748210840281\n",
      "Epoch 91: 1423.1531702368743\n",
      "Epoch 92: 1421.771026852585\n",
      "Epoch 93: 1420.4274983895677\n",
      "Epoch 94: 1419.121967994741\n",
      "Epoch 95: 1417.85251878131\n",
      "Epoch 96: 1416.618930517208\n",
      "Epoch 97: 1415.4196022436731\n",
      "Epoch 98: 1414.2534379121803\n",
      "Epoch 99: 1413.1202843011845\n",
      "Epoch 100: 1412.0180716720365\n",
      "Epoch 101: 1410.9467244467564\n",
      "Epoch 102: 1409.9050737058833\n",
      "Epoch 103: 1408.89239564538\n",
      "Epoch 104: 1407.9075303567308\n",
      "Epoch 105: 1406.9502103584152\n",
      "Epoch 106: 1406.0192385521673\n",
      "Epoch 107: 1405.1141311767556\n",
      "Epoch 108: 1404.2334141191982\n",
      "Epoch 109: 1403.3773468952804\n",
      "Epoch 110: 1402.5446293339842\n",
      "Epoch 111: 1401.7349663263276\n",
      "Epoch 112: 1400.9475360775277\n",
      "Epoch 113: 1400.1815872419447\n",
      "Epoch 114: 1399.4366472427334\n",
      "Epoch 115: 1398.7121980247043\n",
      "Epoch 116: 1398.0075749322064\n",
      "Epoch 117: 1397.3223697323174\n",
      "Epoch 118: 1396.655994380514\n",
      "Epoch 119: 1396.007601584707\n",
      "Epoch 120: 1395.3772896343753\n",
      "Epoch 121: 1394.7637101475682\n",
      "Epoch 122: 1394.1668273763996\n",
      "Epoch 123: 1393.5865733389344\n",
      "Epoch 124: 1393.021867629318\n",
      "Epoch 125: 1392.472776920313\n",
      "Epoch 126: 1391.938410587254\n",
      "Epoch 127: 1391.4184658789918\n",
      "Epoch 128: 1390.9131654983476\n",
      "Epoch 129: 1390.4211126998775\n",
      "Epoch 130: 1389.9426775354714\n",
      "Epoch 131: 1389.4770981903587\n",
      "Epoch 132: 1389.0241417735815\n",
      "Epoch 133: 1388.5833784611452\n",
      "Epoch 134: 1388.1547465622425\n",
      "Epoch 135: 1387.7372929602861\n",
      "Epoch 136: 1387.3316521396239\n",
      "Epoch 137: 1386.9367964785724\n",
      "Epoch 138: 1386.5526603758335\n",
      "Epoch 139: 1386.1787038090683\n",
      "Epoch 140: 1385.8150548090537\n",
      "Epoch 141: 1385.4611479015578\n",
      "Epoch 142: 1385.1165423563548\n",
      "Epoch 143: 1384.7815280691498\n",
      "Epoch 144: 1384.4554683289357\n",
      "Epoch 145: 1384.138334988838\n",
      "Epoch 146: 1383.8294674903154\n",
      "Epoch 147: 1383.5289615853912\n",
      "Epoch 148: 1383.2364399525381\n",
      "Epoch 149: 1382.9520691292626\n",
      "Epoch 150: 1382.6752086154052\n",
      "Epoch 151: 1382.4059331026815\n",
      "Epoch 152: 1382.1432160139084\n",
      "Epoch 153: 1381.888013112403\n",
      "Epoch 154: 1381.6396434292906\n",
      "Epoch 155: 1381.3982806368954\n",
      "Epoch 156: 1381.1632603832654\n",
      "Epoch 157: 1380.9345475690704\n",
      "Epoch 158: 1380.7120186963252\n",
      "Epoch 159: 1380.495076908242\n",
      "Epoch 160: 1380.2841590515204\n",
      "Epoch 161: 1380.0794104380268\n",
      "Epoch 162: 1379.8794701929603\n",
      "Epoch 163: 1379.6850017231136\n",
      "Epoch 164: 1379.4955938337814\n",
      "Epoch 165: 1379.311432883853\n",
      "Epoch 166: 1379.1322444223222\n",
      "Epoch 167: 1378.9577923899606\n",
      "Epoch 168: 1378.78820801207\n",
      "Epoch 169: 1378.6226752897103\n",
      "Epoch 170: 1378.4619516418093\n",
      "Epoch 171: 1378.3055354129701\n",
      "Epoch 172: 1378.1535155858312\n",
      "Epoch 173: 1378.0053531215303\n",
      "Epoch 174: 1377.8612266211283\n",
      "Epoch 175: 1377.7208245027632\n",
      "Epoch 176: 1377.5844444887978\n",
      "Epoch 177: 1377.4512746135395\n",
      "Epoch 178: 1377.322003744188\n",
      "Epoch 179: 1377.1964420058898\n",
      "Epoch 180: 1377.074079519936\n",
      "Epoch 181: 1376.9544125036114\n",
      "Epoch 182: 1376.8382534022842\n",
      "Epoch 183: 1376.7253248478685\n",
      "Epoch 184: 1376.615561938002\n",
      "Epoch 185: 1376.5090338772252\n",
      "Epoch 186: 1376.4042203795343\n",
      "Epoch 187: 1376.3026261088394\n",
      "Epoch 188: 1376.2043083501715\n",
      "Epoch 189: 1376.1077688158978\n",
      "Epoch 190: 1376.014278970304\n",
      "Epoch 191: 1375.923193903906\n",
      "Epoch 192: 1375.834507550512\n",
      "Epoch 193: 1375.7485046528634\n",
      "Epoch 194: 1375.6645021466982\n",
      "Epoch 195: 1375.5828334575608\n",
      "Epoch 196: 1375.5036152707678\n",
      "Epoch 197: 1375.4262490506683\n",
      "Epoch 198: 1375.3509326371409\n",
      "Epoch 199: 1375.27760489285\n",
      "Epoch 200: 1375.2062579861708\n",
      "Epoch 201: 1375.13669401833\n",
      "Epoch 202: 1375.0691815373443\n",
      "Epoch 203: 1375.0034145017464\n",
      "Epoch 204: 1374.9390782053981\n",
      "Epoch 205: 1374.8766797333956\n",
      "Epoch 206: 1374.8162391363155\n",
      "Epoch 207: 1374.7572120172638\n",
      "Epoch 208: 1374.6994612103417\n",
      "Epoch 209: 1374.6433730338301\n",
      "Epoch 210: 1374.5889025557608\n",
      "Epoch 211: 1374.535820750963\n",
      "Epoch 212: 1374.4842864651055\n",
      "Epoch 213: 1374.4341764315254\n",
      "Epoch 214: 1374.3854633747112\n",
      "Epoch 215: 1374.337523273769\n",
      "Epoch 216: 1374.2913775110528\n",
      "Epoch 217: 1374.2460821923755\n",
      "Epoch 218: 1374.2020888172444\n",
      "Epoch 219: 1374.1595250935782\n",
      "Epoch 220: 1374.1181572179\n",
      "Epoch 221: 1374.0778816895825\n",
      "Epoch 222: 1374.03845865173\n",
      "Epoch 223: 1373.9999448777664\n",
      "Epoch 224: 1373.9622253882033\n",
      "Epoch 225: 1373.9259022013061\n",
      "Epoch 226: 1373.8904620316766\n",
      "Epoch 227: 1373.856228521892\n",
      "Epoch 228: 1373.8225913374197\n",
      "Epoch 229: 1373.7895650863647\n",
      "Epoch 230: 1373.7583670204594\n",
      "Epoch 231: 1373.7271225622721\n",
      "Epoch 232: 1373.6968980062575\n",
      "Epoch 233: 1373.6677185353778\n",
      "Epoch 234: 1373.6389451161735\n",
      "Epoch 235: 1373.611369707045\n",
      "Epoch 236: 1373.5843941079718\n",
      "Epoch 237: 1373.5581540614367\n",
      "Epoch 238: 1373.5330037112747\n",
      "Epoch 239: 1373.5076385686796\n",
      "Epoch 240: 1373.4836317676873\n",
      "Epoch 241: 1373.46010944673\n",
      "Epoch 242: 1373.4368869931925\n",
      "Epoch 243: 1373.4144959719408\n",
      "Epoch 244: 1373.3927740554016\n",
      "Epoch 245: 1373.3715223712582\n",
      "Epoch 246: 1373.3509849494412\n",
      "Epoch 247: 1373.3312105210055\n",
      "Epoch 248: 1373.3117018668424\n",
      "Epoch 249: 1373.2927823584705\n",
      "Epoch 250: 1373.2740412063542\n",
      "Epoch 251: 1373.2563415758666\n",
      "Epoch 252: 1373.2382830161423\n",
      "Epoch 253: 1373.2213756264675\n",
      "Epoch 254: 1373.2042392286517\n",
      "Epoch 255: 1373.1885771318562\n",
      "Epoch 256: 1373.1727025416635\n",
      "Epoch 257: 1373.1575059117306\n",
      "Epoch 258: 1373.142580596464\n",
      "Epoch 259: 1373.127878696436\n",
      "Epoch 260: 1373.1142668482803\n",
      "Epoch 261: 1373.10031744412\n",
      "Epoch 262: 1373.086844518071\n",
      "Epoch 263: 1373.0736477758203\n",
      "Epoch 264: 1373.0610503838175\n",
      "Epoch 265: 1373.0489278577622\n",
      "Epoch 266: 1373.0364658974465\n",
      "Epoch 267: 1373.0249635435287\n",
      "Epoch 268: 1373.0133795610495\n",
      "Epoch 269: 1373.0022719828855\n",
      "Epoch 270: 1372.9912579017025\n",
      "Epoch 271: 1372.980678468233\n",
      "Epoch 272: 1372.9705514404036\n",
      "Epoch 273: 1372.9604487738438\n",
      "Epoch 274: 1372.9508376582748\n",
      "Epoch 275: 1372.9413043139946\n",
      "Epoch 276: 1372.932165061434\n",
      "Epoch 277: 1372.9230752083517\n",
      "Epoch 278: 1372.914236838619\n",
      "Epoch 279: 1372.9061138409943\n",
      "Epoch 280: 1372.8977695398387\n",
      "Epoch 281: 1372.8898516034797\n",
      "Epoch 282: 1372.8819157247033\n",
      "Epoch 283: 1372.8745605711426\n",
      "Epoch 284: 1372.8668015152216\n",
      "Epoch 285: 1372.8596764327515\n",
      "Epoch 286: 1372.852898428128\n",
      "Epoch 287: 1372.845943942666\n",
      "Epoch 288: 1372.8391884175085\n",
      "Epoch 289: 1372.8326883947566\n",
      "Epoch 290: 1372.8264995337952\n",
      "Epoch 291: 1372.8201995371353\n",
      "Epoch 292: 1372.8144319866385\n",
      "Epoch 293: 1372.8085320095222\n",
      "Epoch 294: 1372.8030060182016\n",
      "Epoch 295: 1372.7973164277416\n",
      "Epoch 296: 1372.7918111298766\n",
      "Epoch 297: 1372.786514822926\n",
      "Epoch 298: 1372.7816731802054\n",
      "Epoch 299: 1372.7770171619597\n",
      "Epoch 300: 1372.772145213116\n",
      "Epoch 301: 1372.76731651028\n",
      "Epoch 302: 1372.7630803528286\n",
      "Epoch 303: 1372.758811155955\n",
      "Epoch 304: 1372.754205225479\n",
      "Epoch 305: 1372.7500643006392\n",
      "Epoch 306: 1372.7460853840623\n",
      "Epoch 307: 1372.7421255551633\n",
      "Epoch 308: 1372.7383924367882\n",
      "Epoch 309: 1372.734635834183\n",
      "Epoch 310: 1372.7311582238901\n",
      "Epoch 311: 1372.7278899053733\n",
      "Epoch 312: 1372.724008357241\n",
      "Epoch 313: 1372.7207981135164\n",
      "Epoch 314: 1372.7172683690276\n",
      "Epoch 315: 1372.7141144431773\n",
      "Epoch 316: 1372.7108935344786\n",
      "Epoch 317: 1372.7081006140936\n",
      "Epoch 318: 1372.7044008061998\n",
      "Epoch 319: 1372.7018117166701\n",
      "Epoch 320: 1372.698693071093\n",
      "Epoch 321: 1372.695864209107\n",
      "Epoch 322: 1372.6931133170922\n",
      "Epoch 323: 1372.690809098028\n",
      "Epoch 324: 1372.6881678828172\n",
      "Epoch 325: 1372.6856517209894\n",
      "Epoch 326: 1372.6834185620148\n",
      "Epoch 327: 1372.6813597920395\n",
      "Epoch 328: 1372.6794962812037\n",
      "Epoch 329: 1372.6771652230195\n",
      "Epoch 330: 1372.6749074899014\n",
      "Epoch 331: 1372.6730474162669\n",
      "Epoch 332: 1372.6709667827402\n",
      "Epoch 333: 1372.6686595806054\n",
      "Epoch 334: 1372.6670471720752\n",
      "Epoch 335: 1372.665406789808\n",
      "Epoch 336: 1372.6634427174217\n",
      "Epoch 337: 1372.661397156971\n",
      "Epoch 338: 1372.6593071328741\n",
      "Epoch 339: 1372.65746798047\n",
      "Epoch 340: 1372.6559263758716\n",
      "Epoch 341: 1372.654064614858\n",
      "Epoch 342: 1372.6527032561246\n",
      "Epoch 343: 1372.6512112667162\n",
      "Epoch 344: 1372.6498549715393\n",
      "Epoch 345: 1372.6481710665282\n",
      "Epoch 346: 1372.6467376557134\n",
      "Epoch 347: 1372.6459614215862\n",
      "Epoch 348: 1372.644713699108\n",
      "Epoch 349: 1372.6433914239917\n",
      "Epoch 350: 1372.6421596684627\n",
      "Epoch 351: 1372.6409092737097\n",
      "Epoch 352: 1372.6398155256397\n",
      "Epoch 353: 1372.6385743525766\n",
      "Epoch 354: 1372.6375219105255\n",
      "Epoch 355: 1372.6359100476616\n",
      "Epoch 356: 1372.6350952777125\n",
      "Epoch 357: 1372.6339799101863\n",
      "Epoch 358: 1372.6330804363602\n",
      "Epoch 359: 1372.6321883393186\n",
      "Epoch 360: 1372.6311653958899\n",
      "Epoch 361: 1372.6304747426793\n",
      "Epoch 362: 1372.6293132383198\n",
      "Epoch 363: 1372.6285964754366\n",
      "Epoch 364: 1372.6278285291933\n",
      "Epoch 365: 1372.6269265718404\n",
      "Epoch 366: 1372.625976584497\n",
      "Epoch 367: 1372.625497749164\n",
      "Epoch 368: 1372.6247594760996\n",
      "Epoch 369: 1372.6240450647615\n",
      "Epoch 370: 1372.6235989467018\n",
      "Epoch 371: 1372.622669290219\n",
      "Epoch 372: 1372.6219414579016\n",
      "Epoch 373: 1372.621309038429\n",
      "Epoch 374: 1372.621044004957\n",
      "Epoch 375: 1372.6201889053696\n",
      "Epoch 376: 1372.6199190921727\n",
      "Epoch 377: 1372.6193259549993\n",
      "Epoch 378: 1372.618993088603\n",
      "Epoch 379: 1372.6183420213915\n",
      "Epoch 380: 1372.6177721186764\n",
      "Epoch 381: 1372.617447506104\n",
      "Epoch 382: 1372.6169520722967\n",
      "Epoch 383: 1372.6167619107734\n",
      "Epoch 384: 1372.6164631055933\n",
      "Epoch 385: 1372.6158967663844\n",
      "Epoch 386: 1372.6156787666537\n",
      "Epoch 387: 1372.615407415089\n",
      "Epoch 388: 1372.6151524150655\n",
      "Epoch 389: 1372.6151516033071\n",
      "Epoch 390: 1372.6148483604193\n",
      "Epoch 391: 1372.614528124531\n",
      "Epoch 392: 1372.6148047298193\n",
      "Epoch 393: 1372.614329379939\n",
      "Epoch 394: 1372.6142386957295\n",
      "Epoch 395: 1372.6142354628869\n",
      "Epoch 396: 1372.614301090439\n",
      "Epoch 397: 1372.6138626159657\n",
      "Epoch 398: 1372.6137693261817\n",
      "Epoch 399: 1372.61368795165\n",
      "Epoch 400: 1372.6135430101838\n",
      "Epoch 401: 1372.6135253842388\n",
      "Epoch 402: 1372.6132166747536\n",
      "Epoch 403: 1372.613216759903\n",
      "Epoch 404: 1372.6128685155086\n",
      "Epoch 405: 1372.6128253503925\n",
      "Epoch 406: 1372.6127832638365\n",
      "Epoch 407: 1372.6125411838293\n",
      "Epoch 408: 1372.6123950814917\n",
      "Epoch 409: 1372.6123837622858\n",
      "Epoch 410: 1372.6120519914798\n",
      "Epoch 411: 1372.6119527696144\n",
      "Epoch 412: 1372.6120200036537\n",
      "Epoch 413: 1372.6117533438262\n",
      "Epoch 414: 1372.6112312156529\n",
      "Epoch 415: 1372.6112642195963\n",
      "Epoch 416: 1372.611204359503\n",
      "Epoch 417: 1372.6110019421294\n",
      "Epoch 418: 1372.6109646182686\n",
      "Epoch 419: 1372.6110246997505\n",
      "Epoch 420: 1372.610783570579\n",
      "Epoch 421: 1372.6107090136834\n",
      "Epoch 422: 1372.6105055291027\n",
      "Epoch 423: 1372.610419255637\n",
      "Epoch 424: 1372.6104929837443\n",
      "Epoch 425: 1372.6100239519562\n",
      "Epoch 426: 1372.610004063873\n",
      "Epoch 427: 1372.6100583495129\n",
      "Epoch 428: 1372.6096637667645\n",
      "Epoch 429: 1372.609632386338\n",
      "Epoch 430: 1372.6096187425512\n",
      "Epoch 431: 1372.609428484525\n",
      "Epoch 432: 1372.609182774311\n",
      "Epoch 433: 1372.6089930896248\n",
      "Epoch 434: 1372.6088745217949\n",
      "Epoch 435: 1372.6088387079183\n",
      "Epoch 436: 1372.6086537802503\n",
      "Epoch 437: 1372.6086110919714\n",
      "Epoch 438: 1372.608385471361\n",
      "Epoch 439: 1372.608594394156\n",
      "Epoch 440: 1372.6082025645744\n",
      "Epoch 441: 1372.6079179779404\n",
      "Epoch 442: 1372.6078974625893\n",
      "Epoch 443: 1372.6076180871044\n",
      "Epoch 444: 1372.607774827452\n",
      "Epoch 445: 1372.607610063184\n",
      "Epoch 446: 1372.607570480023\n",
      "Epoch 447: 1372.6072714633885\n",
      "Epoch 448: 1372.607373404361\n",
      "Epoch 449: 1372.6070958453984\n",
      "Epoch 450: 1372.6068102114257\n",
      "Epoch 451: 1372.606534247597\n",
      "Epoch 452: 1372.6066366597302\n",
      "Epoch 453: 1372.606274291873\n",
      "Epoch 454: 1372.6065625796716\n",
      "Epoch 455: 1372.6062988660165\n",
      "Epoch 456: 1372.606183145018\n",
      "Epoch 457: 1372.606041320023\n",
      "Epoch 458: 1372.6058423824254\n",
      "Epoch 459: 1372.6055906521422\n",
      "Epoch 460: 1372.605587087217\n",
      "Epoch 461: 1372.6054962327082\n",
      "Epoch 462: 1372.605467571389\n",
      "Epoch 463: 1372.6054684512671\n",
      "Epoch 464: 1372.6054684512671\n",
      "Epoch 465: 1372.6054684512671\n",
      "Epoch 466: 1372.6054684512671\n",
      "Epoch 467: 1372.6054684512671\n",
      "Epoch 468: 1372.6054684512671\n",
      "Epoch 469: 1372.6054684512671\n",
      "Epoch 470: 1372.6054684512671\n",
      "Epoch 471: 1372.6054684512671\n",
      "Epoch 472: 1372.6054684512671\n",
      "Epoch 473: 1372.6054684512671\n",
      "Epoch 474: 1372.6054684512671\n",
      "Epoch 475: 1372.6054684512671\n",
      "Epoch 476: 1372.6054684512671\n",
      "Epoch 477: 1372.6054684512671\n",
      "Epoch 478: 1372.6054684512671\n",
      "Epoch 479: 1372.6054684512671\n",
      "Epoch 480: 1372.6054684512671\n",
      "Epoch 481: 1372.6054684512671\n",
      "Epoch 482: 1372.6054684512671\n",
      "Epoch 483: 1372.6054684512671\n",
      "Epoch 484: 1372.6054684512671\n",
      "Epoch 485: 1372.6054684512671\n",
      "Epoch 486: 1372.6054684512671\n",
      "Epoch 487: 1372.6054684512671\n",
      "Epoch 488: 1372.6054684512671\n",
      "Epoch 489: 1372.6054684512671\n",
      "Epoch 490: 1372.6054684512671\n",
      "Epoch 491: 1372.6054684512671\n",
      "Epoch 492: 1372.6054684512671\n",
      "Epoch 493: 1372.6054684512671\n",
      "Epoch 494: 1372.6054684512671\n",
      "Epoch 495: 1372.6054684512671\n",
      "Epoch 496: 1372.6054684512671\n",
      "Epoch 497: 1372.6054684512671\n",
      "Epoch 498: 1372.6054684512671\n",
      "Epoch 499: 1372.6054684512671\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "# Step 7: initialize the necessary variables, in this case, w and b\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    writer = writer = tf.summary.FileWriter('./my_graph/03/liniear_reg', sess.graph)\n",
    "\n",
    "    # Step 8: train the model\n",
    "    for i in range(500):\n",
    "        total_loss = 0\n",
    "        for x, y in data:\n",
    "            # Session runs optimizer to minimize loss and fetch the value of loss\n",
    "            # TO DO: write sess.run()\n",
    "            _, l = sess.run([optimizer, loss], {X: x, Y: y})\n",
    "            total_loss += l\n",
    "        print(\"Epoch {0}: {1}\".format(i, total_loss/n_samples))\n",
    "    w_value, b_value = sess.run([W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/X/wKipQJo5blgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c991b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "X, Y = data.T[0], data.T[1]\n",
    "plt.plot(X, Y, 'bo', label='Real data')\n",
    "plt.plot(X, X * w_value + b_value, 'r', label='Predicted data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1a 0.526012\n",
      "1b 0.0\n",
      "1c [[ True False False]\n",
      " [ True False False]]\n",
      "1d [array([[ 2],\n",
      "       [ 4],\n",
      "       [ 6],\n",
      "       [ 8],\n",
      "       [ 9],\n",
      "       [11],\n",
      "       [14],\n",
      "       [16],\n",
      "       [18]]), array([[ 31.19073486],\n",
      "       [ 30.97266006],\n",
      "       [ 38.08450317],\n",
      "       [ 34.94445419],\n",
      "       [ 34.45999146],\n",
      "       [ 36.01657104],\n",
      "       [ 30.20379066],\n",
      "       [ 33.71149445],\n",
      "       [ 36.05556488]], dtype=float32)]\n",
      "1e [array([1, 2, 3, 4, 5], dtype=int32), array([[1, 0, 0, 0, 0],\n",
      "       [0, 2, 0, 0, 0],\n",
      "       [0, 0, 3, 0, 0],\n",
      "       [0, 0, 0, 4, 0],\n",
      "       [0, 0, 0, 0, 5]], dtype=int32)]\n",
      "1f [array([[ 0.34534502,  0.82925189,  0.21526563,  0.57343876,  0.31970906,\n",
      "         0.64633453,  0.08908033,  0.99385345,  0.19428527,  0.93551767],\n",
      "       [ 0.42690301,  0.28044963,  0.02792346,  0.51211035,  0.88860786,\n",
      "         0.33595657,  0.37886655,  0.16072166,  0.34818399,  0.07799566],\n",
      "       [ 0.7742579 ,  0.32868195,  0.26638508,  0.44240415,  0.10927701,\n",
      "         0.19124532,  0.7937572 ,  0.24629784,  0.13890886,  0.15344739],\n",
      "       [ 0.28302383,  0.85772669,  0.52116036,  0.95394349,  0.92741489,\n",
      "         0.07105958,  0.39411688,  0.39057457,  0.11513638,  0.5251528 ],\n",
      "       [ 0.52295339,  0.53634131,  0.86911702,  0.9961139 ,  0.63917053,\n",
      "         0.58583105,  0.97854602,  0.64245009,  0.26667678,  0.87845349],\n",
      "       [ 0.50487125,  0.80535793,  0.57003891,  0.83553052,  0.47074699,\n",
      "         0.38011038,  0.989434  ,  0.9432385 ,  0.1849792 ,  0.8599956 ],\n",
      "       [ 0.70694315,  0.81062531,  0.55611444,  0.9557631 ,  0.74643064,\n",
      "         0.62098622,  0.50297868,  0.06563675,  0.91475773,  0.600389  ],\n",
      "       [ 0.73357701,  0.90850317,  0.0209347 ,  0.52229786,  0.55675006,\n",
      "         0.11817575,  0.21820426,  0.9005028 ,  0.61458302,  0.80735362],\n",
      "       [ 0.7913208 ,  0.06371486,  0.67929828,  0.07879984,  0.85026217,\n",
      "         0.64159894,  0.59065902,  0.08798945,  0.26528335,  0.08362257],\n",
      "       [ 0.39263105,  0.16277969,  0.89602268,  0.78947282,  0.96026051,\n",
      "         0.85279417,  0.54319406,  0.70329177,  0.75394118,  0.06334829]], dtype=float32), -0.050927546]\n",
      "1g [ 5  2  3  5 10  6  2  3  4  2  1  1  0  9]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simple TensorFlow exercises\n",
    "You should thoroughly test your code\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "###############################################################################\n",
    "# 1a: Create two random 0-d tensors x and y of any distribution.\n",
    "# Create a TensorFlow object that returns x + y if x > y, and x - y otherwise.\n",
    "# Hint: look up tf.cond()\n",
    "# I do the first problem for you\n",
    "###############################################################################\n",
    "\n",
    "x = tf.random_uniform([])  # Empty array as shape creates a scalar.\n",
    "y = tf.random_uniform([])\n",
    "out = tf.cond(tf.less(x, y), lambda: tf.add(x, y), lambda: tf.sub(x, y))\n",
    "with tf.Session() as sess:\n",
    "    print(\"1a\", sess.run(out))\n",
    "\n",
    "###############################################################################\n",
    "# 1b: Create two 0-d tensors x and y randomly selected from -1 and 1.\n",
    "# Return x + y if x < y, x - y if x > y, 0 otherwise.\n",
    "# Hint: Look up tf.case().\n",
    "###############################################################################\n",
    "\n",
    "x1 = tf.random_uniform([], minval=1, maxval=1)\n",
    "y1 = tf.random_uniform([], minval=1, maxval=1)\n",
    "out1 = tf.case({tf.less(x1, y1): lambda: tf.add(x1, y1),\n",
    "                tf.greater(x1, y1): lambda: tf.sub(x1, y1)},\n",
    "               exclusive=True,\n",
    "               default=lambda: tf.constant(0, dtype=tf.float32),\n",
    "               name=\"case\")\n",
    "with tf.Session() as sess:\n",
    "    print(\"1b\", sess.run(out1))\n",
    "\n",
    "###############################################################################\n",
    "# 1c: Create the tensor x of the value [[0, -2, -1], [0, 1, 2]] \n",
    "# and y as a tensor of zeros with the same shape as x.\n",
    "# Return a boolean tensor that yields Trues if x equals y element-wise.\n",
    "# Hint: Look up tf.equal().\n",
    "###############################################################################\n",
    "\n",
    "x2 = tf.constant([[0, -2, -1], [0, 1, 2]], dtype=tf.float64)\n",
    "y2 = tf.zeros(3, 2)\n",
    "out2 = tf.equal(x2, y2)\n",
    "with tf.Session() as sess:\n",
    "    print(\"1c\", sess.run(out2))\n",
    "\n",
    "###############################################################################\n",
    "# 1d: Create the tensor x of value \n",
    "# [29.05088806,  27.61298943,  31.19073486,  29.35532951,\n",
    "#  30.97266006,  26.67541885,  38.08450317,  20.74983215,\n",
    "#  34.94445419,  34.45999146,  29.06485367,  36.01657104,\n",
    "#  27.88236427,  20.56035233,  30.20379066,  29.51215172,\n",
    "#  33.71149445,  28.59134293,  36.05556488,  28.66994858].\n",
    "# Get the indices of elements in x whose values are greater than 30.\n",
    "# Hint: Use tf.where().\n",
    "# Then extract elements whose values are greater than 30.\n",
    "# Hint: Use tf.gather().\n",
    "###############################################################################\n",
    "\n",
    "x = tf.constant([\n",
    "    29.05088806,  27.61298943,  31.19073486,  29.35532951,\n",
    "    30.97266006,  26.67541885,  38.08450317,  20.74983215,\n",
    "    34.94445419,  34.45999146,  29.06485367,  36.01657104,\n",
    "    27.88236427,  20.56035233,  30.20379066,  29.51215172,\n",
    "    33.71149445,  28.59134293,  36.05556488,  28.66994858])\n",
    "\n",
    "indices = tf.where(tf.greater(x, 30))\n",
    "values = tf.gather(x, indices)\n",
    "with tf.Session() as sess:\n",
    "    print(\"1d\", sess.run([indices, values]))\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 1e: Create a diagnoal 2-d tensor of size 6 x 6 with the diagonal values of 1,\n",
    "# 2, ..., 6\n",
    "# Hint: Use tf.range() and tf.diag().\n",
    "###############################################################################\n",
    "\n",
    "ranges = tf.range(1, 6)\n",
    "out = tf.diag(ranges)\n",
    "with tf.Session() as sess:\n",
    "    print(\"1e\", sess.run([ranges, out]))\n",
    "\n",
    "###############################################################################\n",
    "# 1f: Create a random 2-d tensor of size 10 x 10 from any distribution.\n",
    "# Calculate its determinant.\n",
    "# Hint: Look at tf.matrix_determinant().\n",
    "###############################################################################\n",
    "\n",
    "x = tf.random_uniform((10, 10))\n",
    "with tf.Session() as sess:\n",
    "    print(\"1f\", sess.run([x, tf.matrix_determinant(x)]))\n",
    "\n",
    "###############################################################################\n",
    "# 1g: Create tensor x with value [5, 2, 3, 5, 10, 6, 2, 3, 4, 2, 1, 1, 0, 9].\n",
    "# Return the unique elements in x\n",
    "# Hint: use tf.unique(). Keep in mind that tf.unique() returns a tuple.\n",
    "###############################################################################\n",
    "\n",
    "x = tf.constant([5, 2, 3, 5, 10, 6, 2, 3, 4, 2, 1, 1, 0, 9])\n",
    "with tf.Session() as sess:\n",
    "    print(\"1g\", sess.run([x, tf.unique(x)])[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1h [array([ 0.68748057,  0.04837799,  0.17514455], dtype=float32), array([ 0.10534561,  0.39624679,  0.74295247], dtype=float32), 1.4978117]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# 1h: Create two tensors x and y of shape 300 from any normal distribution,\n",
    "# as long as they are from the same distribution.\n",
    "# Use tf.less() and tf.select() to return:\n",
    "# - The mean squared error of (x - y) if the average of all elements in (x - y)\n",
    "#   is negative, or\n",
    "# - The sum of absolute value of all elements in the tensor (x - y) otherwise.\n",
    "# Hint: see the Huber loss function in the lecture slides 3.\n",
    "###############################################################################\n",
    "\n",
    "x = tf.random_uniform([3])\n",
    "y = tf.random_uniform([3])\n",
    "mean = tf.reduce_mean(x)\n",
    "condition = tf.less(mean, 0)\n",
    "error = tf.reduce_mean(tf.square(x - y))\n",
    "\n",
    "selector = tf.select(condition, error, tf.reduce_sum(tf.abs(x - y)))\n",
    "with tf.Session() as sess:\n",
    "    print(\"1h\", sess.run([x, y, selector]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\"\"\"\n",
    "Starter code for logistic regression model to solve OCR task \n",
    "with MNIST in TensorFlow\n",
    "MNIST dataset: yann.lecun.com/exdb/mnist/\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time\n",
    "\n",
    "# Define paramaters for the model\n",
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "n_epochs = 25\n",
    "\n",
    "# Step 1: Read in data\n",
    "# using TF Learn's built in function to load MNIST data to the folder data/mnist\n",
    "mnist = input_data.read_data_sets('data/mnist', one_hot=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Step 2: create placeholders for features and labels\n",
    "# each image in the MNIST data is of shape 28*28 = 784\n",
    "# therefore, each image is represented with a 1x784 tensor\n",
    "# there are 10 classes for each image, corresponding to digits 0 - 9.\n",
    "\n",
    "X = tf.placeholder(tf.float32, [batch_size, 784], name=\"image\")\n",
    "Y = tf.placeholder(tf.float32, [batch_size, 10], name=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Step 3: create weights and bias\n",
    "# weights and biases are initialized to 0\n",
    "# shape of w depends on the dimension of X and Y so that Y = X * w + b\n",
    "# shape of b depends on Y\n",
    "\n",
    "w = tf.Variable(tf.zeros([784, 10]), name=\"w\", dtype=tf.float32)\n",
    "b = tf.Variable(tf.zeros([batch_size, 10]), name=\"b\", dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# the model that returns the logits.\n",
    "# this logits will be later passed through softmax layer\n",
    "# to get the probability distribution of possible label of the image\n",
    "# DO NOT DO SOFTMAX HERE\n",
    "logits = tf.matmul(X, w) + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Step 5: define loss function\n",
    "# use cross entropy loss of the real labels with the softmax of logits\n",
    "# use the method:\n",
    "# tf.nn.softmax_cross_entropy_with_logits(logits, Y)\n",
    "# then use tf.reduce_mean to get the mean loss of the batch\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 0: 2.097315984172421\n",
      "Average loss epoch 1: 1.765452989331492\n",
      "Average loss epoch 2: 1.5246752631136309\n",
      "Average loss epoch 3: 1.3485371032794873\n",
      "Average loss epoch 4: 1.216713368475854\n",
      "Average loss epoch 5: 1.1160752795515083\n",
      "Average loss epoch 6: 1.0364799481449705\n",
      "Average loss epoch 7: 0.9728833074336285\n",
      "Average loss epoch 8: 0.9206114080680278\n",
      "Average loss epoch 9: 0.876955541836354\n",
      "Average loss epoch 10: 0.8399688697361446\n",
      "Average loss epoch 11: 0.808252501182067\n",
      "Average loss epoch 12: 0.7805878475551561\n",
      "Average loss epoch 13: 0.7564174268907045\n",
      "Average loss epoch 14: 0.734704334558029\n",
      "Average loss epoch 15: 0.7154601653972705\n",
      "Average loss epoch 16: 0.6980303079931887\n",
      "Average loss epoch 17: 0.6824469014759108\n",
      "Average loss epoch 18: 0.6682929511948343\n",
      "Average loss epoch 19: 0.6552176249749733\n",
      "Average loss epoch 20: 0.6433441968230934\n",
      "Average loss epoch 21: 0.6321726276741161\n",
      "Average loss epoch 22: 0.6220983190414233\n",
      "Average loss epoch 23: 0.612566378914115\n",
      "Average loss epoch 24: 0.6038651062058402\n",
      "Total time: 14.852237939834595 seconds\n",
      "Optimization Finished!\n",
      "Accuracy 0.8714\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\tstart_time = time.time()\n",
    "\tsess.run(tf.global_variables_initializer())\t\n",
    "\tn_batches = int(mnist.train.num_examples/batch_size)\n",
    "\tfor i in range(n_epochs): # train the model n_epochs times\n",
    "\t\ttotal_loss = 0\n",
    "\n",
    "\t\tfor _ in range(n_batches):\n",
    "\t\t\tX_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "\t\t\t# TO-DO: run optimizer + fetch loss_batch\n",
    "\t\t\t_, loss_batch = sess.run([optimizer, loss], {X: X_batch, Y: Y_batch})\n",
    "\t\t\ttotal_loss += loss_batch\n",
    "\t\tprint('Average loss epoch {0}: {1}'.format(i, total_loss/n_batches))\n",
    "\n",
    "\tprint('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "\n",
    "\tprint('Optimization Finished!') # should be around 0.35 after 25 epochs\n",
    "\n",
    "\t# test the model\n",
    "\tn_batches = int(mnist.test.num_examples/batch_size)\n",
    "\ttotal_correct_preds = 0\n",
    "\tfor i in range(n_batches):\n",
    "\t\tX_batch, Y_batch = mnist.test.next_batch(batch_size)\n",
    "\t\t_, loss_batch, logits_batch = sess.run([optimizer, loss, logits], feed_dict={X: X_batch, Y:Y_batch}) \n",
    "\t\tpreds = tf.nn.softmax(logits_batch)\n",
    "\t\tcorrect_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y_batch, 1))\n",
    "\t\taccuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32)) # need numpy.count_nonzero(boolarr) :(\n",
    "\t\ttotal_correct_preds += sess.run(accuracy)\t\n",
    "\t\n",
    "\tprint('Accuracy {0}'.format(total_correct_preds/mnist.test.num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
