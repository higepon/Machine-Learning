{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is this?\n",
    "For stock prices prediction, we will probably text input or sentiment input.\n",
    "To get familiar with those kind of input, I think it's good to learn them by developing Chatbot.\n",
    "It's also fun :)\n",
    "\n",
    "### Steps\n",
    "- Input data: Use my own twitter data\n",
    "- Shape the input data\n",
    "- Build a model\n",
    "- Train\n",
    "- Test\n",
    "- Visualize\n",
    "\n",
    "### Input Data\n",
    "I'm going to use my own twitter data.\n",
    "\n",
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Install mecab\n",
    "    # Thanks to http://qiita.com/taroc/items/b9afd914432da08dafc8\n",
    "    brew install mecab\n",
    "    brew install mecab-ipadic\n",
    "    pip install mecab-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " , BOS/EOS\n",
      "æœ€è¿‘ , åè©\n",
      "è‡ªåˆ† , åè©\n",
      "ã¯ , åŠ©è©\n",
      "ã©ã“ , åè©\n",
      "ã« , åŠ©è©\n",
      "è¡Œã“ , å‹•è©\n",
      "ã† , åŠ©å‹•è©\n",
      "ã¨ , åŠ©è©\n",
      "ã— , å‹•è©\n",
      "ã¦ã‚‹ , å‹•è©\n",
      "ã‚“ , åè©\n",
      "ã ã‚ , åŠ©å‹•è©\n",
      "ã¨ , åŠ©è©\n",
      "æ€ã„ , å‹•è©\n",
      "ãªãŒã‚‰ , åŠ©è©\n",
      "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° , åè©\n",
      "ã— , å‹•è©\n",
      "ã¦ã‚‹ , å‹•è©\n",
      "ğŸ˜‰ , è¨˜å·\n",
      " , BOS/EOS\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "mt = MeCab.Tagger(\"mecabrc\")\n",
    "mt.parse('') # prevent string gc-ed huh?\n",
    "node = mt.parseToNode(\"æœ€è¿‘è‡ªåˆ†ã¯ã©ã“ã«è¡Œã“ã†ã¨ã—ã¦ã‚‹ã‚“ã ã‚ã¨æ€ã„ãªãŒã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã‚‹ğŸ˜‰\")\n",
    "while node:\n",
    "    word = node.surface\n",
    "    pos = node.feature.split(\",\")[0]\n",
    "    print('{0} , {1}'.format(word, pos))\n",
    "    node = node.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOS/EOS',\n",
       " 'æœ€è¿‘',\n",
       " 'è‡ªåˆ†',\n",
       " 'ã¯',\n",
       " 'ã©ã“',\n",
       " 'ã«',\n",
       " 'è¡Œã“',\n",
       " 'ã†',\n",
       " 'ã¨',\n",
       " 'ã—',\n",
       " 'ã¦ã‚‹',\n",
       " 'ã‚“',\n",
       " 'ã ã‚',\n",
       " 'ã¨',\n",
       " 'æ€ã„',\n",
       " 'ãªãŒã‚‰',\n",
       " 'ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°',\n",
       " 'ã—',\n",
       " 'ã¦ã‚‹',\n",
       " 'ğŸ˜‰',\n",
       " 'BOS/EOS']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import MeCab\n",
    "mt = MeCab.Tagger(\"mecabrc\")\n",
    "mt.parse('') # prevent string gc-ed huh?\n",
    "\n",
    "def tokenize(text):\n",
    "    ret = []\n",
    "    node = mt.parseToNode(text)\n",
    "    while node:\n",
    "        word = node.surface\n",
    "        if word == '':\n",
    "            word = 'BOS/EOS'\n",
    "        ret.append(word)\n",
    "        node = node.next\n",
    "    return ret\n",
    "\n",
    "tokenize(\"æœ€è¿‘è‡ªåˆ†ã¯ã©ã“ã«è¡Œã“ã†ã¨ã—ã¦ã‚‹ã‚“ã ã‚ã¨æ€ã„ãªãŒã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã‚‹ğŸ˜‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Seq2Seq\n",
    "See http://qiita.com/halhorn/items/dc10596942ef4be54af5\n",
    "\n",
    "    git clone https://www.github.com/datalogai/recurrentshop.git\n",
    "    cd recurrentshop\n",
    "    python setup.py install\n",
    "    pip3 install git+https://github.com/farizrahman4u/seq2seq.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from seq2seq.models import SimpleSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SimpleSeq2Seq(input_dim=1, hidden_dim=10, output_length=8, output_dim=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.models.Sequential object at 0x11b30ea58>\n",
      "cMhNVE7msy\n"
     ]
    }
   ],
   "source": [
    "import random as random\n",
    "import string as string\n",
    "\n",
    "def randomString(n):\n",
    "    return ''.join([random.choice(string.ascii_letters + string.digits) for i in range(n)])\n",
    "\n",
    "print(randomString(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['g7EAd', 'przaF', 'UjkGS', 'ymZxw', 'Lc2E9', 'XbzpE', 'Er1Rc', 'moe90', 'em9SN', '6T11D', 'd9DGY', 'KRlXR', '3Z6iK', 'cFJQ9', 'PhcRD', 'ubm02', 'bQWgD', 'k536R', 'isOkm', 'XC2lM', 'Ct8Gp', 'FNZKB', 'R4bJK', 'R2ljI', 'd2VAx', 'sUyDB', '5QJpn', 'FzLDC', 'XVIEC', 'luv6W', 'WEm8Q', 'qGcDl', '6dmqr', '5UZwT', 'Y4Y2V', 'fex2t', 'NVO6c', 'AzVVn', 'SZris', 'EVL6i', 'QAt5e', 'eURi5', 'WOmFd', 'EGi5t', 'cIMfe', 'vWmmn', 'c4UpQ', 'MQ3dX', '7vnmg', '58eR3']\n"
     ]
    }
   ],
   "source": [
    "## Create Input data\n",
    "num_input = 50\n",
    "print([randomString(5) for _ in range(num_input)])\n",
    "\n",
    "## never mind, this is not necesary for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "- Understand http://qiita.com/halhorn/items/dc10596942ef4be54af5\n",
    "- Make above work here\n",
    "- Change above a little bit\n",
    "- Use 10 pairs of replies and train then predict\n",
    "- Run above via real data\n",
    "- Can we use word2vec above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "## from http://qiita.com/halhorn/items/dc10596942ef4be54af5\n",
    "from seq2seq.models import SimpleSeq2Seq\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# ã‚·ãƒ³ãƒ—ãƒ«ãª Seq2Seq ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰\n",
    "model = SimpleSeq2Seq(input_dim=1, hidden_dim=10, output_length=8, output_dim=1)\n",
    "\n",
    "# å­¦ç¿’ã®è¨­å®š\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ä½œæˆ\n",
    "# å…¥åŠ›ï¼š1000ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä½ç›¸ã‚’æŒã¤ä¸€æ¬¡å…ƒã®ã‚µã‚¤ãƒ³æ³¢\n",
    "# å‡ºåŠ›ï¼šå„å…¥åŠ›ã®é€†ä½ç›¸ã®ã‚µã‚¤ãƒ³æ³¢\n",
    "a = np.random.random(1000)\n",
    "x = np.array([np.sin([[p] for p in np.arange(0, 0.8, 0.1)] + aa) for aa in a])\n",
    "print(x.shape)\n",
    "y = -x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model target: expected recurrentcontainer_16 to have shape (None, 16, 1) but got array with shape (1000, 8, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-282a36153bce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# å­¦ç¿’\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# æœªå­¦ç¿’ã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/higepon/.pyenv/versions/anaconda3-4.1.1/envs/tensorflow/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/higepon/.pyenv/versions/anaconda3-4.1.1/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1117\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/higepon/.pyenv/versions/anaconda3-4.1.1/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1031\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                    \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m                                    exception_prefix='model target')\n\u001b[0m\u001b[1;32m   1034\u001b[0m         sample_weights = standardize_sample_weights(sample_weight,\n\u001b[1;32m   1035\u001b[0m                                                     self.output_names)\n",
      "\u001b[0;32m/Users/higepon/.pyenv/versions/anaconda3-4.1.1/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model target: expected recurrentcontainer_16 to have shape (None, 16, 1) but got array with shape (1000, 8, 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "# å­¦ç¿’\n",
    "model.fit(x, y, nb_epoch=5, batch_size=32)\n",
    "\n",
    "# æœªå­¦ç¿’ã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ\n",
    "x_test = np.array([np.sin([[p] for p in np.arange(0, 0.8, 0.1)] + aa) for aa in np.arange(0, 1.0, 0.1)])\n",
    "y_test = -x_test\n",
    "print(model.evaluate(x_test, y_test, batch_size=32))\n",
    "\n",
    "# æœªå­¦ç¿’ã®ãƒ‡ãƒ¼ã‚¿ã§ç”Ÿæˆ\n",
    "predicted = model.predict(x_test, batch_size=32)\n",
    "\n",
    "plt.plot(np.arange(0, 0.8, 0.1), [xx[0] for xx in x_test[9]])\n",
    "plt.plot(np.arange(0, 0.8, 0.1), [xx[0] for xx in predicted[9]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conversations = [\n",
    "    (\"ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è¨¼åˆ¸ä¼šç¤¾ã€ETFãªã©ã®å•†å“ã®è‰¯ã•ã€æ‰‹æ•°æ–™ã®å®‰ã•ã§è€ƒãˆã‚‹ã¨æœ€è¿‘ã¯ã©ã“ãŒã„ã„ã‚“ã ã‚ã†ï¼Ÿï¼’ã¤ã»ã©å£åº§æŒã£ã¦ã‚‹ã‚“ã ã‘ã©5å¹´å‰ãã‚‰ã„ã«é¸ã‚“ã ã‚‚ã®ã ã‹ã‚‰ãƒ™ã‚¹ãƒˆã‹ã‚ã‹ã‚‰ãšã€‚ @karino2012 ã•ã‚“ã¨ã‹ã©ã†ã§ã™ã‹ã€‚\", \"æœ€è¿‘ã®äº‹ã¯è‡ªåˆ†ã‚‚åˆ†ã‹ã‚‰ã‚“ã§ã™ã­ã‡ã€‚7å¹´ãã‚‰ã„å‰ã‹ã‚‰E-Tradeã¨æ¥½å¤©ã®2ã¤ãŒã‚ã‚Œã°è‰¯ã•ãã†ã ã£ãŸã‘ã©ã€ã€ã€\"),\n",
    "    (\"ãªãœæ±ºå®šæœ¨ã‚’ä½¿ã†äººãŒå¤šã„ã‚“ã ã‚ã†ã€‚\", \"è­˜åˆ¥èƒ½åŠ›ãŒé«˜ãã¦å®‰å®šã—ã¦ã„ã‚‹ã‹ã‚‰ã˜ã‚ƒãªã„ã‹ã€‚\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len_tweets 62\n",
      "max_len_replies 16\n",
      "[['BOS/EOS', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³', 'è¨¼åˆ¸', 'ä¼šç¤¾', 'ã€', 'ETF', 'ãªã©', 'ã®', 'å•†å“', 'ã®', 'è‰¯', 'ã•', 'ã€', 'æ‰‹æ•°æ–™', 'ã®', 'å®‰', 'ã•', 'ã§', 'è€ƒãˆã‚‹', 'ã¨', 'æœ€è¿‘', 'ã¯', 'ã©ã“', 'ãŒ', 'ã„ã„', 'ã‚“', 'ã ã‚', 'ã†', 'ï¼Ÿ', 'ï¼’ã¤', 'ã»ã©', 'å£åº§', 'æŒã£', 'ã¦ã‚‹', 'ã‚“', 'ã ', 'ã‘ã©', '5', 'å¹´', 'å‰', 'ãã‚‰ã„', 'ã«', 'é¸ã‚“', 'ã ', 'ã‚‚ã®', 'ã ', 'ã‹ã‚‰', 'ãƒ™ã‚¹ãƒˆ', 'ã‹', 'ã‚ã‹ã‚‰', 'ãš', 'ã€‚', '@', 'karino', '2012', 'ã•ã‚“', 'ã¨ã‹', 'ã©ã†', 'ã§ã™', 'ã‹', 'ã€‚', 'BOS/EOS'], ['BOS/EOS', 'æœ€è¿‘', 'ã®', 'äº‹', 'ã¯', 'è‡ªåˆ†', 'ã‚‚', 'åˆ†ã‹ã‚‰', 'ã‚“', 'ã§ã™', 'ã­ã‡', 'ã€‚', '7', 'å¹´', 'ãã‚‰ã„', 'å‰', 'ã‹ã‚‰', 'E', '-', 'Trade', 'ã¨', 'æ¥½å¤©', 'ã®', '2', 'ã¤', 'ãŒ', 'ã‚ã‚Œ', 'ã°', 'è‰¯', 'ã•', 'ãã†', 'ã ã£', 'ãŸ', 'ã‘ã©', 'ã€', 'ã€', 'ã€', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS']]\n"
     ]
    }
   ],
   "source": [
    "tweets = conversations[0]\n",
    "replies = conversations[1]\n",
    "\n",
    "tweets_lemmatized = [tokenize(sentence) for sentence in tweets]\n",
    "max_len_tweets = len(max(tweets_lemmatized, key=len))\n",
    "print(\"max_len_tweets\", max_len_tweets)\n",
    "\n",
    "replies_lemmatized = [tokenize(sentence) for sentence in replies]\n",
    "max_len_replies = len(max(replies_lemmatized, key=len))\n",
    "print(\"max_len_replies\", max_len_replies)\n",
    "\n",
    "tweets_lemmatized = [tweet + ['BOS/EOS'] * (max_len_tweets - len(tweet)) for tweet in tweets_lemmatized]\n",
    "replies_lemmatized = [reply + ['BOS/EOS'] * (max_len_replies - len(reply)) for reply in replies_lemmatized]\n",
    "\n",
    "# pad BOS/EOS\n",
    "print(tweets_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words {'ã¦', 'ãƒ™ã‚¹ãƒˆ', '7', 'ã•ã‚“', 'BOS/EOS', '2', 'æœ¨', 'ãªã©', 'ãŸ', 'ãã‚‰ã„', 'ã®', 'ã‚‚', 'ã«', 'é¸ã‚“', 'æ±ºå®š', 'ã†', 'è‰¯', 'ã§', 'ä¼šç¤¾', 'ãã†', 'ã€', 'ã»ã©', 'ã¨', 'å®‰', 'ã­ã‡', 'è€ƒãˆã‚‹', 'è¨¼åˆ¸', 'ã°', 'ã¦ã‚‹', 'ã‹', 'ã‚ã‹ã‚‰', '2012', 'Trade', 'åˆ†ã‹ã‚‰', 'ã¤', 'ã‚ã‚Œ', 'å£åº§', 'E', 'ãªãœ', 'ã©ã†', 'è­˜åˆ¥', '5', 'ãªã„', 'å®‰å®š', 'ãš', 'ã˜ã‚ƒ', 'ã‘ã©', 'ä½¿ã†', 'ã—', 'äº‹', 'ï¼’ã¤', 'ã ã£', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³', 'è‡ªåˆ†', 'ã€‚', 'å•†å“', 'ãŒ', 'ï¼Ÿ', 'ETF', 'å¹´', 'æŒã£', 'ã ', 'ã„ã‚‹', '-', 'ã©ã“', 'èƒ½åŠ›', 'é«˜ã', 'æœ€è¿‘', '@', 'ã•', 'å‰', 'æ‰‹æ•°æ–™', 'ã‚‚ã®', 'ã‚“', 'ã‹ã‚‰', 'å¤šã„', 'ã¨ã‹', 'ã‚’', 'karino', 'ã¯', 'ã„ã„', 'äºº', 'ã ã‚', 'ã§ã™', 'æ¥½å¤©'}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "words = set(itertools.chain(*tweets_lemmatized)).union(set(itertools.chain(*replies_lemmatized)))\n",
    "print(\"words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2idx {'ã¦': 0, 'ãƒ™ã‚¹ãƒˆ': 1, 'å¤šã„': 75, 'ãš': 44, '7': 2, 'ã•ã‚“': 3, 'BOS/EOS': 4, 'æœ¨': 6, 'ãªã©': 7, 'ã—': 48, 'ãŸ': 8, 'ï¼’ã¤': 50, 'karino': 78, 'ãã‚‰ã„': 9, 'ã®': 10, 'è‡ªåˆ†': 53, 'ã«': 12, 'é¸ã‚“': 13, 'ã ã£': 51, 'ã‹ã‚‰': 74, 'ã‚‚ã®': 72, 'ã˜ã‚ƒ': 45, 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³': 52, 'æ±ºå®š': 14, 'ã†': 15, 'è‰¯': 16, 'ã€‚': 54, 'ã ': 61, 'ã§': 17, 'ã‚ã‚Œ': 35, 'ä¼šç¤¾': 18, '2': 5, '@': 68, 'ï¼Ÿ': 57, 'ãã†': 19, 'ETF': 58, 'å¹´': 59, 'ã‘ã©': 46, 'ã€': 20, 'æŒã£': 60, 'ã­ã‡': 24, 'ã¨': 22, 'å®‰': 23, 'äºº': 81, 'é«˜ã': 66, 'ã»ã©': 21, '-': 63, 'ã©ã“': 64, 'è¨¼åˆ¸': 26, 'ã°': 27, 'ã¦ã‚‹': 28, 'E': 37, 'ã‹': 29, 'ã‚ã‹ã‚‰': 30, 'ä½¿ã†': 47, '2012': 31, 'ã ã‚': 82, 'ã•': 69, 'äº‹': 49, 'æ‰‹æ•°æ–™': 71, 'ã‚“': 73, 'å•†å“': 55, 'å‰': 70, 'èƒ½åŠ›': 65, 'ã§ã™': 83, 'Trade': 32, 'åˆ†ã‹ã‚‰': 33, 'ã¤': 34, 'å£åº§': 36, 'ã‚‚': 11, 'ã¯': 79, 'ãªãœ': 38, 'ã‚’': 77, 'ã„ã„': 80, 'ã©ã†': 39, 'æœ€è¿‘': 67, 'è­˜åˆ¥': 40, 'ã„ã‚‹': 62, '5': 41, 'ãŒ': 56, 'è€ƒãˆã‚‹': 25, 'ãªã„': 42, 'æ¥½å¤©': 84, 'ã¨ã‹': 76, 'å®‰å®š': 43}\n",
      "idx2word ['ã¦', 'ãƒ™ã‚¹ãƒˆ', '7', 'ã•ã‚“', 'BOS/EOS', '2', 'æœ¨', 'ãªã©', 'ãŸ', 'ãã‚‰ã„', 'ã®', 'ã‚‚', 'ã«', 'é¸ã‚“', 'æ±ºå®š', 'ã†', 'è‰¯', 'ã§', 'ä¼šç¤¾', 'ãã†', 'ã€', 'ã»ã©', 'ã¨', 'å®‰', 'ã­ã‡', 'è€ƒãˆã‚‹', 'è¨¼åˆ¸', 'ã°', 'ã¦ã‚‹', 'ã‹', 'ã‚ã‹ã‚‰', '2012', 'Trade', 'åˆ†ã‹ã‚‰', 'ã¤', 'ã‚ã‚Œ', 'å£åº§', 'E', 'ãªãœ', 'ã©ã†', 'è­˜åˆ¥', '5', 'ãªã„', 'å®‰å®š', 'ãš', 'ã˜ã‚ƒ', 'ã‘ã©', 'ä½¿ã†', 'ã—', 'äº‹', 'ï¼’ã¤', 'ã ã£', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³', 'è‡ªåˆ†', 'ã€‚', 'å•†å“', 'ãŒ', 'ï¼Ÿ', 'ETF', 'å¹´', 'æŒã£', 'ã ', 'ã„ã‚‹', '-', 'ã©ã“', 'èƒ½åŠ›', 'é«˜ã', 'æœ€è¿‘', '@', 'ã•', 'å‰', 'æ‰‹æ•°æ–™', 'ã‚‚ã®', 'ã‚“', 'ã‹ã‚‰', 'å¤šã„', 'ã¨ã‹', 'ã‚’', 'karino', 'ã¯', 'ã„ã„', 'äºº', 'ã ã‚', 'ã§ã™', 'æ¥½å¤©']\n"
     ]
    }
   ],
   "source": [
    "# dictionaries for converting words to integers and vice versa\n",
    "word2idx = dict((v, i) for i, v in enumerate(words))\n",
    "print(\"word2idx\", word2idx)\n",
    "\n",
    "idx2word = list(words)\n",
    "print(\"idx2word\", idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets_idx [[4, 52, 26, 18, 20, 58, 7, 10, 55, 10, 16, 69, 20, 71, 10, 23, 69, 17, 25, 22, 67, 79, 64, 56, 80, 73, 82, 15, 57, 50, 21, 36, 60, 28, 73, 61, 46, 41, 59, 70, 9, 12, 13, 61, 72, 61, 74, 1, 29, 30, 44, 54, 68, 78, 31, 3, 76, 39, 83, 29, 54, 4], [4, 67, 10, 49, 79, 53, 11, 33, 73, 83, 24, 54, 2, 59, 9, 70, 74, 37, 63, 32, 22, 84, 10, 5, 34, 56, 35, 27, 16, 69, 19, 51, 8, 46, 20, 20, 20, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]]\n",
      "replies_idx [[4, 38, 14, 6, 77, 47, 81, 56, 75, 73, 82, 15, 54, 4, 4, 4], [4, 40, 65, 56, 66, 0, 43, 48, 0, 62, 74, 45, 42, 29, 54, 4]]\n"
     ]
    }
   ],
   "source": [
    "# convert the sentences a numpy array\n",
    "to_idx = lambda x: [word2idx[word] for word in x]\n",
    "\n",
    "tweets_idx = [to_idx(tweet) for tweet in tweets_lemmatized]\n",
    "replies_idx = [to_idx(tweet) for tweet in replies_lemmatized]\n",
    "\n",
    "print(\"tweets_idx\", tweets_idx)\n",
    "print(\"replies_idx\", replies_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (2, 62, 1)\n",
      "Y.shape (2, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(tweets_idx).reshape(-1, max_len_tweets, 1)\n",
    "#print(\"X\", X)\n",
    "print(\"X.shape\", X.shape)\n",
    "\n",
    "Y = np.asarray(replies_idx).reshape(-1, max_len_replies, 1)\n",
    "print(\"Y.shape\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 3s - loss: 2332.6660\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s - loss: 2331.1233\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s - loss: 2329.5732\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s - loss: 2328.0342\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s - loss: 2326.5234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12dbe1f60>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleSeq2Seq(input_dim=1, hidden_dim=10, output_length=max_len_replies, output_dim=1, depth=3)\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.fit(X, Y, nb_epoch=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BOS/EOS', 'ã„ã„', 'äºº', 'ã ã‚', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS', 'BOS/EOS']\n",
      "[4, 80, 81, 82, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00495657],\n",
       "        [ 0.01447026],\n",
       "        [ 0.02855   ],\n",
       "        [ 0.046618  ],\n",
       "        [ 0.06772517],\n",
       "        [ 0.09072167],\n",
       "        [ 0.11441334],\n",
       "        [ 0.13770361],\n",
       "        [ 0.1597044 ],\n",
       "        [ 0.17979693],\n",
       "        [ 0.1976383 ],\n",
       "        [ 0.21312347],\n",
       "        [ 0.22632433],\n",
       "        [ 0.23742503],\n",
       "        [ 0.24666676],\n",
       "        [ 0.25430775]]], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_str=\"ã„ã„äººã ã‚\"\n",
    "lemmatized = tokenize(test_str)\n",
    "lemmatized = lemmatized + ['BOS/EOS'] * (max_len_tweets - len(lemmatized))\n",
    "print(lemmatized)\n",
    "\n",
    "idx = to_idx(lemmatized)\n",
    "print(idx)\n",
    "model.predict(np.array(idx).reshape(1, max_len_tweets, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
