{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is this?\n",
    "In #7 we tried to use Seq2Seql but we couldn't figure it out.\n",
    "Here we're going to use [working example](https://github.com/nicolas-ivanov/debug_seq2seq) step by step, so that we should be able to know what's going on.\n",
    "\n",
    "### Data\n",
    "We gonna use very small data set for faster iterations. Once we're done with whole process, we will increase data size.\n",
    "\n",
    "### word2vec\n",
    "Here we convert our vocabrary to vector, so that we can have smaller dimension and similarities between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=0, size=256, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "window = 5              # window is the maximum distance between the current and predicted word within a sentence.\n",
    "min_count = 1           # ignore all words with total frequency lower than this.\n",
    "max_vocab_size = 20000  # limit RAM during vocabulary building; if there are more unique words than this, then prune the infrequent ones. Every 10 million word types need about 1GB of RAM. Set to None for no limit (default).\n",
    "size = 256              # size is the dimensionality of the feature vectors.\n",
    "workers = 5             # use this many worker threads to train the model (=faster training with multicore machines\n",
    "\n",
    "model = Word2Vec(window=window,\n",
    "                 min_count=min_count,\n",
    "                 max_vocab_size=max_vocab_size,\n",
    "                 size=size,\n",
    "                 workers=workers)\n",
    "print(model)\n",
    "\n",
    "model.build_vocab(tokenized_lines_for_voc)\n",
    "model.train(tokenized_lines_for_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
